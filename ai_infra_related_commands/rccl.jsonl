{"id":"structnccl_config__t","kind":"struct","language":"C++","prot":"public","compoundname":"ncclConfig_t","title":"","briefdescription":"Communicator configuration.","detaileddescription":"Users can assign value to attributes to specify the behavior of a communicator","includes":[],"memberdefs":[{"kind":"variable","id":"structnccl_config__t_1a81b9700436fb7d1d9166f12edf56e3c5","prot":"public","static":"no","mutable":"no","type":"size_t","definition":"size_t ncclConfig_t::size","argsstring":null,"name":"size","briefdescription":null,"detaileddescription":"Should not be touched","inbodydescription":null},{"kind":"variable","id":"structnccl_config__t_1a23cc3b42fd29f9429275cb352313e059","prot":"public","static":"no","mutable":"no","type":"unsigned int","definition":"unsigned int ncclConfig_t::magic","argsstring":null,"name":"magic","briefdescription":null,"detaileddescription":"Should not be touched","inbodydescription":null},{"kind":"variable","id":"structnccl_config__t_1ae12a3889e1d03fca0db598d133e0edab","prot":"public","static":"no","mutable":"no","type":"unsigned int","definition":"unsigned int ncclConfig_t::version","argsstring":null,"name":"version","briefdescription":null,"detaileddescription":"Should not be touched","inbodydescription":null},{"kind":"variable","id":"structnccl_config__t_1a27e6b6a590375b78bac83514a9e2c9cb","prot":"public","static":"no","mutable":"no","type":"int","definition":"int ncclConfig_t::blocking","argsstring":null,"name":"blocking","briefdescription":null,"detaileddescription":"Whether or not calls should block or not","inbodydescription":null},{"kind":"variable","id":"structnccl_config__t_1af9487d36b5260611ed530f1f89d8b949","prot":"public","static":"no","mutable":"no","type":"int","definition":"int ncclConfig_t::cgaClusterSize","argsstring":null,"name":"cgaClusterSize","briefdescription":null,"detaileddescription":"Cooperative group array cluster size","inbodydescription":null},{"kind":"variable","id":"structnccl_config__t_1a1c9c02c9a3df279d487ac4072f95c5e7","prot":"public","static":"no","mutable":"no","type":"int","definition":"int ncclConfig_t::minCTAs","argsstring":null,"name":"minCTAs","briefdescription":null,"detaileddescription":"Minimum number of cooperative thread arrays (blocks)","inbodydescription":null},{"kind":"variable","id":"structnccl_config__t_1a797bd8e7d303965c13ead0cbcc932323","prot":"public","static":"no","mutable":"no","type":"int","definition":"int ncclConfig_t::maxCTAs","argsstring":null,"name":"maxCTAs","briefdescription":null,"detaileddescription":"Maximum number of cooperative thread arrays (blocks)","inbodydescription":null},{"kind":"variable","id":"structnccl_config__t_1a203cd704ccf9b2bbf7ebcadc10ed8208","prot":"public","static":"no","mutable":"no","type":"const char *","definition":"const char* ncclConfig_t::netName","argsstring":null,"name":"netName","briefdescription":null,"detaileddescription":"Force NCCL to use a specfic network","inbodydescription":null},{"kind":"variable","id":"structnccl_config__t_1a8bf85f02eb593c0a21eefe495f6779ec","prot":"public","static":"no","mutable":"no","type":"int","definition":"int ncclConfig_t::splitShare","argsstring":null,"name":"splitShare","briefdescription":null,"detaileddescription":"Allow communicators to share resources","inbodydescription":null}]}
{"id":"structnccl_unique_id","kind":"struct","language":"C++","prot":"public","compoundname":"ncclUniqueId","title":"","briefdescription":"Opaque unique id used to initialize communicators.","detaileddescription":"The must be passed to all participating ranks","includes":[],"memberdefs":[{"kind":"variable","id":"structnccl_unique_id_1ad3c9cf7193a0235017e44ad5049f1acd","prot":"public","static":"no","mutable":"no","type":"char","definition":"char ncclUniqueId::internal[NCCL_UNIQUE_ID_BYTES]","argsstring":"[NCCL_UNIQUE_ID_BYTES]","name":"internal","briefdescription":null,"detaileddescription":"Opaque array>","inbodydescription":null}]}
{"id":"rccl_8h_8in","kind":"file","language":"C++","prot":null,"compoundname":"rccl.h.in","title":"","briefdescription":"","detaileddescription":"","includes":["hip\/hip_runtime.h","hip\/hip_fp16.h","limits.h"],"memberdefs":[{"kind":"define","id":"rccl_8h_8in_1a36f232f35fefb92a0d1c5c63a1e30a16","prot":"public","static":"no","name":"NCCL_H_","briefdescription":null,"detaileddescription":null,"inbodydescription":null,"initializer":null},{"kind":"define","id":"rccl_8h_8in_1ad6945b46656a203cbf0fedc2d2858b6a","prot":"public","static":"no","name":"NCCL_MAJOR","briefdescription":null,"detaileddescription":null,"inbodydescription":null,"initializer":"${NCCL_MAJOR}"},{"kind":"define","id":"rccl_8h_8in_1aa4f380af20fbea50af11f0c5a500943e","prot":"public","static":"no","name":"NCCL_MINOR","briefdescription":null,"detaileddescription":null,"inbodydescription":null,"initializer":"${NCCL_MINOR}"},{"kind":"define","id":"rccl_8h_8in_1a7ba95a3cac1ea909898b5e5730e6a5eb","prot":"public","static":"no","name":"NCCL_PATCH","briefdescription":null,"detaileddescription":null,"inbodydescription":null,"initializer":"${NCCL_PATCH}"},{"kind":"define","id":"rccl_8h_8in_1a430afd74146640aa27410c0ba9940977","prot":"public","static":"no","name":"NCCL_SUFFIX","briefdescription":null,"detaileddescription":null,"inbodydescription":null,"initializer":"\"${NCCL_SUFFIX}\""},{"kind":"define","id":"rccl_8h_8in_1a8dc3054e537bc884f8114c03d317063e","prot":"public","static":"no","name":"NCCL_VERSION_CODE","briefdescription":null,"detaileddescription":null,"inbodydescription":null,"initializer":"${NCCL_VERSION}"},{"kind":"define","id":"rccl_8h_8in_1aebcdcd428dab18306fe558e74f7832fc","prot":"public","static":"no","name":"NCCL_VERSION","briefdescription":null,"detaileddescription":null,"inbodydescription":null,"initializer":"(((X) <= 2 && (Y) <= 8) ? (X) * 1000 + (Y) * 100 + (Z) : (X) * 10000 + (Y) * 100 + (Z))"},{"kind":"define","id":"rccl_8h_8in_1a03b47f5c188b0a7864bfad1ecb361d5c","prot":"public","static":"no","name":"RCCL_BFLOAT16","briefdescription":null,"detaileddescription":null,"inbodydescription":null,"initializer":"1"},{"kind":"define","id":"rccl_8h_8in_1a5d3717d9142413e39cc5e5062751dbdf","prot":"public","static":"no","name":"RCCL_GATHER_SCATTER","briefdescription":null,"detaileddescription":null,"inbodydescription":null,"initializer":"1"},{"kind":"define","id":"rccl_8h_8in_1af3db26c7af7496eefe0f484ab36d86f9","prot":"public","static":"no","name":"RCCL_ALLTOALLV","briefdescription":null,"detaileddescription":null,"inbodydescription":null,"initializer":"1"},{"kind":"define","id":"rccl_8h_8in_1a901f24cc9fa9f81df18b0af46f51c36f","prot":"public","static":"no","name":"NCCL_COMM_NULL","briefdescription":null,"detaileddescription":null,"inbodydescription":null,"initializer":"NULL"},{"kind":"define","id":"rccl_8h_8in_1a48f5c022eb064c561468066bb988db57","prot":"public","static":"no","name":"NCCL_UNIQUE_ID_BYTES","briefdescription":null,"detaileddescription":null,"inbodydescription":null,"initializer":"128"},{"kind":"define","id":"rccl_8h_8in_1ad7f5b1f570b5ab67518a70cf343e2cbc","prot":"public","static":"no","name":"NCCL_CONFIG_UNDEF_INT","briefdescription":null,"detaileddescription":null,"inbodydescription":null,"initializer":"INT_MIN"},{"kind":"define","id":"rccl_8h_8in_1aea18d54be4f85861e4b451b2c6cff1b5","prot":"public","static":"no","name":"NCCL_CONFIG_UNDEF_PTR","briefdescription":null,"detaileddescription":null,"inbodydescription":null,"initializer":"NULL"},{"kind":"define","id":"rccl_8h_8in_1af964217805f3bd7320464a7a8e9763e7","prot":"public","static":"no","name":"NCCL_SPLIT_NOCOLOR","briefdescription":null,"detaileddescription":null,"inbodydescription":null,"initializer":"-1"},{"kind":"define","id":"group__rccl__config__type_1ga01bcf2fc58fdeb3d705c375a9e8e6641","prot":"public","static":"no","name":"NCCL_CONFIG_INITIALIZER","briefdescription":null,"detaileddescription":null,"inbodydescription":null,"initializer":"{ \\ sizeof(ncclConfig_t), \/* size *\/ \\ 0xcafebeef, \/* magic *\/ \\ NCCL_VERSION(NCCL_MAJOR, NCCL_MINOR, NCCL_PATCH), \/* version *\/ \\ NCCL_CONFIG_UNDEF_INT, \/* blocking *\/ \\ NCCL_CONFIG_UNDEF_INT, \/* cgaClusterSize *\/ \\ NCCL_CONFIG_UNDEF_INT, \/* minCTAs *\/ \\ NCCL_CONFIG_UNDEF_INT, \/* maxCTAs *\/ \\ NCCL_CONFIG_UNDEF_PTR, \/* netName *\/ \\ NCCL_CONFIG_UNDEF_INT \/* splitShare *\/ \\ }"},{"kind":"enum","id":"group__rccl__result__code_1ga55fb03de49ceafd58b85851c12fd2f9b","prot":"public","static":"no","strong":"no","type":null,"name":"ncclResult_t","briefdescription":"Result type.","detaileddescription":"Return codes aside from ncclSuccess indicate that a call has failed","inbodydescription":null,"initializer":null,"enumvalue":[{"id":"group__rccl__result__code_1gga55fb03de49ceafd58b85851c12fd2f9bac0fdf720be5323a352e2f7d326a95e0c","prot":"public","name":"ncclSuccess","initializer":"= 0","briefdescription":"","detaileddescription":"No error"},{"id":"group__rccl__result__code_1gga55fb03de49ceafd58b85851c12fd2f9baf558f3a7d72c4a1afe21713f21b5462b","prot":"public","name":"ncclUnhandledCudaError","initializer":"= 1","briefdescription":"","detaileddescription":"Unhandled HIP error"},{"id":"group__rccl__result__code_1gga55fb03de49ceafd58b85851c12fd2f9ba6c5fc68e72a0bf32b63896dae693aabd","prot":"public","name":"ncclSystemError","initializer":"= 2","briefdescription":"","detaileddescription":"Unhandled system error"},{"id":"group__rccl__result__code_1gga55fb03de49ceafd58b85851c12fd2f9ba848f01c9a93891fd6cb1f75f75a4225d","prot":"public","name":"ncclInternalError","initializer":"= 3","briefdescription":"","detaileddescription":"Internal Error - Please report to RCCL developers"},{"id":"group__rccl__result__code_1gga55fb03de49ceafd58b85851c12fd2f9baf080ab7ddae4277af1c1ed8ad86c0064","prot":"public","name":"ncclInvalidArgument","initializer":"= 4","briefdescription":"","detaileddescription":"Invalid argument"},{"id":"group__rccl__result__code_1gga55fb03de49ceafd58b85851c12fd2f9ba39ae1f6eaeeece5db98c0e4f16792dd9","prot":"public","name":"ncclInvalidUsage","initializer":"= 5","briefdescription":"","detaileddescription":"Invalid usage"},{"id":"group__rccl__result__code_1gga55fb03de49ceafd58b85851c12fd2f9ba54943f2d63afabd25967e6af1c7c695e","prot":"public","name":"ncclRemoteError","initializer":"= 6","briefdescription":"","detaileddescription":"Remote process exited or there was a network error"},{"id":"group__rccl__result__code_1gga55fb03de49ceafd58b85851c12fd2f9ba49ac32824d76708227cce42a79ad5451","prot":"public","name":"ncclInProgress","initializer":"= 7","briefdescription":"","detaileddescription":"RCCL operation in progress"},{"id":"group__rccl__result__code_1gga55fb03de49ceafd58b85851c12fd2f9ba4a31f5fab974f5bc93c5fd83628ed589","prot":"public","name":"ncclNumResults","initializer":"= 8","briefdescription":"","detaileddescription":"Number of result types"}]},{"kind":"enum","id":"group__rccl__api__enumerations_1ga87c10957f4ed69dac2782c16553587d2","prot":"public","static":"no","strong":"no","type":null,"name":"ncclRedOp_dummy_t","briefdescription":"Dummy reduction enumeration.","detaileddescription":"Dummy reduction enumeration used to determine value for ncclMaxRedOp","inbodydescription":null,"initializer":null,"enumvalue":[{"id":"group__rccl__api__enumerations_1gga87c10957f4ed69dac2782c16553587d2a96255037fda3c88bbc9dc43f041d2537","prot":"public","name":"ncclNumOps_dummy","initializer":"= 5","briefdescription":"","detaileddescription":""}]},{"kind":"enum","id":"group__rccl__api__enumerations_1ga921726a1c391fbb4ecc6e9cf00294524","prot":"public","static":"no","strong":"no","type":null,"name":"ncclRedOp_t","briefdescription":"Reduction operation selector.","detaileddescription":"Enumeration used to specify the various reduction operations ncclNumOps is the number of built-in ncclRedOp_t values and serves as the least possible value for dynamic ncclRedOp_t values constructed by ncclRedOpCreate functions.ncclMaxRedOp is the largest valid value for ncclRedOp_t and is defined to be the largest signed value (since compilers are permitted to use signed enums) that won't grow sizeof(ncclRedOp_t) when compared to previous RCCL versions to maintain ABI compatibility.","inbodydescription":null,"initializer":null,"enumvalue":[{"id":"group__rccl__api__enumerations_1gga921726a1c391fbb4ecc6e9cf00294524a344420f29fe77f9124aa46de1447a43e","prot":"public","name":"ncclSum","initializer":"= 0","briefdescription":"","detaileddescription":"Sum"},{"id":"group__rccl__api__enumerations_1gga921726a1c391fbb4ecc6e9cf00294524aed6b2548a983f976c9b6751c66e525e1","prot":"public","name":"ncclProd","initializer":"= 1","briefdescription":"","detaileddescription":"Product"},{"id":"group__rccl__api__enumerations_1gga921726a1c391fbb4ecc6e9cf00294524aff6a64c28091cc6123a68a328aa518e9","prot":"public","name":"ncclMax","initializer":"= 2","briefdescription":"","detaileddescription":"Max"},{"id":"group__rccl__api__enumerations_1gga921726a1c391fbb4ecc6e9cf00294524a1451e8ae4b66a096d7d7f40ea8efb3d1","prot":"public","name":"ncclMin","initializer":"= 3","briefdescription":"","detaileddescription":"Min"},{"id":"group__rccl__api__enumerations_1gga921726a1c391fbb4ecc6e9cf00294524aff95c7e0300edaaed8d85111f06440b1","prot":"public","name":"ncclAvg","initializer":"= 4","briefdescription":"","detaileddescription":"Average"},{"id":"group__rccl__api__enumerations_1gga921726a1c391fbb4ecc6e9cf00294524a1924e1d9d29535ce44bbe5d26034ca5a","prot":"public","name":"ncclNumOps","initializer":"= 5","briefdescription":"","detaileddescription":"Number of built-in reduction ops"},{"id":"group__rccl__api__enumerations_1gga921726a1c391fbb4ecc6e9cf00294524a595f3f9fac30ac16b0700e152e73aba0","prot":"public","name":"ncclMaxRedOp","initializer":"= 0x7fffffff>>(32-8*sizeof(ncclRedOp_dummy_t))","briefdescription":"","detaileddescription":"Largest value for ncclRedOp_t"}]},{"kind":"enum","id":"group__rccl__api__enumerations_1ga9a37adf1ce63a5edd2f7eda6305b2b9b","prot":"public","static":"no","strong":"no","type":null,"name":"ncclDataType_t","briefdescription":"Data types.","detaileddescription":"Enumeration of the various supported datatype","inbodydescription":null,"initializer":null,"enumvalue":[{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9ba85071680188efee7900241d542e77f06","prot":"public","name":"ncclInt8","initializer":"= 0","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9baba531d24a08b8f7264cf91541cdfff3f","prot":"public","name":"ncclChar","initializer":"= 0","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9bad3d205d5e216795c7fe7d574fb3c72b4","prot":"public","name":"ncclUint8","initializer":"= 1","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9ba26f2406ddd8f3b8e923df2d0302a6a1b","prot":"public","name":"ncclInt32","initializer":"= 2","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9babf08532f223398863c9b168e6b08e7be","prot":"public","name":"ncclInt","initializer":"= 2","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9ba749fbbbfe3992027638ab02e94f13694","prot":"public","name":"ncclUint32","initializer":"= 3","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9bae439a1da80920fdda1b18313eea95507","prot":"public","name":"ncclInt64","initializer":"= 4","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9bac8ba680aba07abcc1c5d18fea2294517","prot":"public","name":"ncclUint64","initializer":"= 5","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9bae6bfae9dbcb7ee80a3a03bc8579acdbe","prot":"public","name":"ncclFloat16","initializer":"= 6","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9ba04d86767f185410a447bd4ebabee287d","prot":"public","name":"ncclHalf","initializer":"= 6","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9ba9ff7882c7811330dcd33cef5df2cfac2","prot":"public","name":"ncclFloat32","initializer":"= 7","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9bab6497c7b7df34db5e51d8e3e146bd266","prot":"public","name":"ncclFloat","initializer":"= 7","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9ba0368d171ce5e7e9324169cbc76ae1200","prot":"public","name":"ncclFloat64","initializer":"= 8","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9ba890cf5618feba1d76287c710c84b2f12","prot":"public","name":"ncclDouble","initializer":"= 8","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9baae6bb61a7c162f64cd8ea078e30890fa","prot":"public","name":"ncclBfloat16","initializer":"= 9","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9ba6ea571a3fe475a98c7b36ffe95d1c37d","prot":"public","name":"ncclNumTypes","initializer":"= 10","briefdescription":"","detaileddescription":""}]},{"kind":"enum","id":"group__rccl__api__custom__redop_1ga0d7ee97426bc0eb7020cb3c9ebef6ea7","prot":"public","static":"no","strong":"no","type":null,"name":"ncclScalarResidence_t","briefdescription":"Location and dereferencing logic for scalar arguments.","detaileddescription":"Enumeration specifying memory location of the scalar argument. Based on where the value is stored, the argument will be dereferenced either while the collective is running (if in device memory), or before the ncclRedOpCreate() function returns (if in host memory).","inbodydescription":null,"initializer":null,"enumvalue":[{"id":"group__rccl__api__custom__redop_1gga0d7ee97426bc0eb7020cb3c9ebef6ea7ae65101c0646f7a5de231132aa4ef30d3","prot":"public","name":"ncclScalarDevice","initializer":"= 0","briefdescription":"","detaileddescription":"Scalar is in device-visible memory"},{"id":"group__rccl__api__custom__redop_1gga0d7ee97426bc0eb7020cb3c9ebef6ea7ad01760269a6bc2661aa9fb7f52568228","prot":"public","name":"ncclScalarHostImmediate","initializer":"= 1","briefdescription":"","detaileddescription":"Scalar is in host-visible memory"}]},{"kind":"typedef","id":"rccl_8h_8in_1a1a769cabbf0902841e33d0dbf0fb8a9c","prot":"public","static":"no","type":"struct ncclComm *","definition":"typedef struct ncclComm* ncclComm_t","argsstring":null,"name":"ncclComm_t","briefdescription":"Opaque handle to communicator.","detaileddescription":"A communicator contains information required to facilitate collective communications calls","inbodydescription":null,"initializer":null},{"kind":"typedef","id":"group__msccl__api_1ga67330717c515e3f41d5c589a84d8fd51","prot":"public","static":"no","type":"int","definition":"typedef int mscclAlgoHandle_t","argsstring":null,"name":"mscclAlgoHandle_t","briefdescription":"Opaque handle to MSCCL algorithm.","detaileddescription":null,"inbodydescription":null,"initializer":null},{"kind":"function","id":"group__rccl__api__version_1gaa94bf928cefe8d1a11a92ec68c640d0d","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"int *","declname":"version","direction":"out","parameterdescription":"Pointer to where version will be stored"}],"type":"ncclResult_t","definition":"ncclResult_t ncclGetVersion","argsstring":"(int *version)","name":"ncclGetVersion","briefdescription":"Return the RCCL_VERSION_CODE of RCCL in the supplied integer.","detaileddescription":"This integer is coded with the MAJOR, MINOR and PATCH level of RCCL.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__api__communicator_1ga53d41b0397871975f6c19bed19f35a88","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclUniqueId *","declname":"uniqueId","direction":"out","parameterdescription":"Pointer to where uniqueId will be stored"}],"type":"ncclResult_t","definition":"ncclResult_t ncclGetUniqueId","argsstring":"(ncclUniqueId *uniqueId)","name":"ncclGetUniqueId","briefdescription":"Generates an ID for ncclCommInitRank.","detaileddescription":"Generates an ID to be used in ncclCommInitRank. ncclGetUniqueId should be called once by a single rank and the ID should be distributed to all ranks in the communicator before using it as a parameter for ncclCommInitRank.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__api__communicator_1ga7f5e9012f8ce9bbb87c19e0fd9030c21","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclComm_t *","declname":"comm","direction":"out","parameterdescription":"Pointer to created communicator"},{"type":"int","declname":"nranks","direction":"in","parameterdescription":"Total number of ranks participating in this communicator"},{"type":"ncclUniqueId","declname":"commId","direction":"in","parameterdescription":"UniqueId required for initialization"},{"type":"int","declname":"rank","direction":"in","parameterdescription":"Current rank to create communicator for. [0 to nranks-1]"},{"type":"ncclConfig_t *","declname":"config","direction":"in","parameterdescription":"Pointer to communicator configuration"}],"type":"ncclResult_t","definition":"ncclResult_t ncclCommInitRankConfig","argsstring":"(ncclComm_t *comm, int nranks, ncclUniqueId commId, int rank, ncclConfig_t *config)","name":"ncclCommInitRankConfig","briefdescription":"Create a new communicator with config.","detaileddescription":"Create a new communicator (multi thread\/process version) with a configuration set by users. See for more details. Each rank is associated to a CUDA device, which has to be set before calling ncclCommInitRank.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__api__communicator_1ga23fea6998061aadac1bdde55648ca40e","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclComm_t *","declname":"comm","direction":"out","parameterdescription":"Pointer to created communicator"},{"type":"int","declname":"nranks","direction":"in","parameterdescription":"Total number of ranks participating in this communicator"},{"type":"ncclUniqueId","declname":"commId","direction":"in","parameterdescription":"UniqueId required for initialization"},{"type":"int","declname":"rank","direction":"in","parameterdescription":"Current rank to create communicator for"}],"type":"ncclResult_t","definition":"ncclResult_t ncclCommInitRank","argsstring":"(ncclComm_t *comm, int nranks, ncclUniqueId commId, int rank)","name":"ncclCommInitRank","briefdescription":"Creates a new communicator (multi thread\/process version).","detaileddescription":"Rank must be between 0 and nranks-1 and unique within a communicator clique. Each rank is associated to a CUDA device, which has to be set before calling ncclCommInitRank. ncclCommInitRank implicitly syncronizes with other ranks, so it must be called by different threads\/processes or use ncclGroupStart\/ncclGroupEnd.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__api__communicator_1gae2b97ef85192c88ce8f2d5cf309855a2","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclComm_t *","declname":"comm","direction":"out","parameterdescription":"Pointer to array of created communicators"},{"type":"int","declname":"ndev","direction":"in","parameterdescription":"Total number of ranks participating in this communicator"},{"type":"const int *","declname":"devlist","direction":"in","parameterdescription":"Array of GPU device indices to create for"}],"type":"ncclResult_t","definition":"ncclResult_t ncclCommInitAll","argsstring":"(ncclComm_t *comm, int ndev, const int *devlist)","name":"ncclCommInitAll","briefdescription":"Creates a clique of communicators (single process version).","detaileddescription":"This is a convenience function to create a single-process communicator clique. Returns an array of ndev newly initialized communicators in comm. comm should be pre-allocated with size at least ndev*sizeof(ncclComm_t). If devlist is NULL, the first ndev HIP devices are used. Order of devlist defines user-order of processors within the communicator.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__api__communicator_1ga2a3f3b807ec33d97618d0d7ac0eb2a91","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator to finalize"}],"type":"ncclResult_t","definition":"ncclResult_t ncclCommFinalize","argsstring":"(ncclComm_t comm)","name":"ncclCommFinalize","briefdescription":"Finalize a communicator.","detaileddescription":"ncclCommFinalize flushes all issued communications and marks communicator state as ncclInProgress. The state will change to ncclSuccess when the communicator is globally quiescent and related resources are freed; then, calling ncclCommDestroy can locally free the rest of the resources (e.g. communicator itself) without blocking.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__api__communicator_1ga333fba6c01bd6fe2a285e5a7929fcd02","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator to destroy"}],"type":"ncclResult_t","definition":"ncclResult_t ncclCommDestroy","argsstring":"(ncclComm_t comm)","name":"ncclCommDestroy","briefdescription":"Frees local resources associated with communicator object.","detaileddescription":"Destroy all local resources associated with the passed in communicator object","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__api__communicator_1ga5fa333fe131f53ef76216d8a95b05a58","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator to abort and destroy"}],"type":"ncclResult_t","definition":"ncclResult_t ncclCommAbort","argsstring":"(ncclComm_t comm)","name":"ncclCommAbort","briefdescription":"Abort any in-progress calls and destroy the communicator object.","detaileddescription":"Frees resources associated with communicator object and aborts any operations that might still be running on the device.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__api__communicator_1gad370ee2fde1d6f518ab289c6cdbe8e9d","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Original communicator object for this rank"},{"type":"int","declname":"color","direction":"in","parameterdescription":"Color to assign this rank"},{"type":"int","declname":"key","direction":"in","parameterdescription":"Key used to order ranks within the same new communicator"},{"type":"ncclComm_t *","declname":"newcomm","direction":"out","parameterdescription":"Pointer to new communicator"},{"type":"ncclConfig_t *","declname":"config","direction":"in","parameterdescription":"Config file for new communicator. May be NULL to inherit from comm"}],"type":"ncclResult_t","definition":"ncclResult_t ncclCommSplit","argsstring":"(ncclComm_t comm, int color, int key, ncclComm_t *newcomm, ncclConfig_t *config)","name":"ncclCommSplit","briefdescription":"Create one or more communicators from an existing one.","detaileddescription":"Creates one or more communicators from an existing one. Ranks with the same color will end up in the same communicator. Within the new communicator, key will be used to order ranks. NCCL_SPLIT_NOCOLOR as color will indicate the rank will not be part of any group and will therefore return a NULL communicator. If config is NULL, the new communicator will inherit the original communicator's configuration","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__api__errcheck_1gabd1cc4f6df988e713f23b549bcb95b56","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclResult_t","declname":"result","direction":"in","parameterdescription":"Result code to get description for"}],"type":"const char *","definition":"const char* ncclGetErrorString","argsstring":"(ncclResult_t result)","name":"ncclGetErrorString","briefdescription":"Returns a string for each result code.","detaileddescription":"Returns a human-readable string describing the given result code.","inbodydescription":null,"initializer":null,"returns":"String containing description of result code."},{"kind":"function","id":"group__rccl__api__errcheck_1ga91fc7cb1d79c972fcbe97d32e9172476","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"is currently unused and can be set to NULL"}],"type":"const char *","definition":"const char* ncclGetLastError","argsstring":"(ncclComm_t comm)","name":"ncclGetLastError","briefdescription":"Returns mesage on last result that occured.","detaileddescription":"Returns a human-readable message of the last error that occurred.","inbodydescription":null,"initializer":null,"returns":"String containing the last result"},{"kind":"function","id":"group__rccl__api__errcheck_1gad7e3ece2064eafde9f01221674f872ac","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator to query"},{"type":"ncclResult_t *","declname":"asyncError","direction":"out","parameterdescription":"Pointer to where result code will be stored"}],"type":"ncclResult_t","definition":"ncclResult_t ncclCommGetAsyncError","argsstring":"(ncclComm_t comm, ncclResult_t *asyncError)","name":"ncclCommGetAsyncError","briefdescription":"Checks whether the comm has encountered any asynchronous errors.","detaileddescription":"Query whether the provided communicator has encountered any asynchronous errors","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__api__comminfo_1gad04d727a6eb4da7c8da5ec90f771b22f","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator to query"},{"type":"int *","declname":"count","direction":"out","parameterdescription":"Pointer to where number of ranks will be stored"}],"type":"ncclResult_t","definition":"ncclResult_t ncclCommCount","argsstring":"(const ncclComm_t comm, int *count)","name":"ncclCommCount","briefdescription":"Gets the number of ranks in the communicator clique.","detaileddescription":"Returns the number of ranks in the communicator clique (as set during initialization)","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__api__comminfo_1ga61c5f1a88f7cabc3c3e1017c424387b9","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator to query"},{"type":"int *","declname":"device","direction":"out","parameterdescription":"Pointer to where the associated ROCm device index will be stored"}],"type":"ncclResult_t","definition":"ncclResult_t ncclCommCuDevice","argsstring":"(const ncclComm_t comm, int *device)","name":"ncclCommCuDevice","briefdescription":"Get the ROCm device index associated with a communicator.","detaileddescription":"Returns the ROCm device number associated with the provided communicator.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__api__comminfo_1ga8f7c6cbb83b9eb549103012829f5ab9f","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator to query"},{"type":"int *","declname":"rank","direction":"out","parameterdescription":"Pointer to where the associated rank will be stored"}],"type":"ncclResult_t","definition":"ncclResult_t ncclCommUserRank","argsstring":"(const ncclComm_t comm, int *rank)","name":"ncclCommUserRank","briefdescription":"Get the rank associated with a communicator.","detaileddescription":"Returns the user-ordered \"rank\" associated with the provided communicator.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__api__custom__redop_1ga35e2028c6f6c40ae4aea90a5076eabfc","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclRedOp_t *","declname":"op","direction":"out","parameterdescription":"Pointer to where newly created custom reduction operator is to be stored"},{"type":"void *","declname":"scalar","direction":"in","parameterdescription":"Pointer to scalar value."},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Scalar value datatype"},{"type":"ncclScalarResidence_t","declname":"residence","direction":"in","parameterdescription":"Memory type of the scalar value"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator to associate with this custom reduction operator"}],"type":"ncclResult_t","definition":"ncclResult_t ncclRedOpCreatePreMulSum","argsstring":"(ncclRedOp_t *op, void *scalar, ncclDataType_t datatype, ncclScalarResidence_t residence, ncclComm_t comm)","name":"ncclRedOpCreatePreMulSum","briefdescription":"Create a custom pre-multiplier reduction operator.","detaileddescription":"Creates a new reduction operator which pre-multiplies input values by a given scalar locally before reducing them with peer values via summation. For use only with collectives launched against and . The residence* argument indicates how\/when the memory pointed to by will be dereferenced. Upon return, the newly created operator's handle is stored in .","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__api__custom__redop_1gad3ed8c2e917e71c3dc4918c1f2641aac","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclRedOp_t","declname":"op","direction":"in","parameterdescription":"Custom reduction operator is to be destroyed"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator associated with this reduction operator"}],"type":"ncclResult_t","definition":"ncclResult_t ncclRedOpDestroy","argsstring":"(ncclRedOp_t op, ncclComm_t comm)","name":"ncclRedOpDestroy","briefdescription":"Destroy custom reduction operator.","detaileddescription":"Destroys the reduction operator . The operator must have been created by ncclRedOpCreatePreMul with the matching communicator . An operator may be destroyed as soon as the last RCCL function which is given that operator returns.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__collective__api_1ga0353a2a2756a84bdc3404fd8ce17be95","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const void *","declname":"sendbuff","direction":"in","parameterdescription":"Local device data buffer to be reduced"},{"type":"void *","declname":"recvbuff","direction":"out","parameterdescription":"Data buffer where result is stored (only for root rank). May be null for other ranks."},{"type":"size_t","declname":"count","direction":"in","parameterdescription":"Number of elements in every send buffer"},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"ncclRedOp_t","declname":"op","direction":"in","parameterdescription":"Reduction operator type"},{"type":"int","declname":"root","direction":"in","parameterdescription":"Rank where result data array will be stored"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t ncclReduce","argsstring":"(const void *sendbuff, void *recvbuff, size_t count, ncclDataType_t datatype, ncclRedOp_t op, int root, ncclComm_t comm, hipStream_t stream)","name":"ncclReduce","briefdescription":"Reduce.","detaileddescription":"Reduces data arrays of length in into using operation. recvbuff* may be NULL on all calls except for root device. root* is the rank (not the HIP device) where data will reside after the operation is complete. In-place operation will happen if sendbuff == recvbuff.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__collective__api_1ga088407ffe8b1b7dc7578a37006d22ab9","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"void *","declname":"buff","direction":"inout","parameterdescription":"Input array on root to be copied to other ranks. Output array for all ranks."},{"type":"size_t","declname":"count","direction":"in","parameterdescription":"Number of elements in data buffer"},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"int","declname":"root","direction":"in","parameterdescription":"Rank owning buffer to be copied to others"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t ncclBcast","argsstring":"(void *buff, size_t count, ncclDataType_t datatype, int root, ncclComm_t comm, hipStream_t stream)","name":"ncclBcast","briefdescription":"(Deprecated) Broadcast (in-place)","detaileddescription":"Copies values from to all other devices. root is the rank (not the CUDA device) where data resides before the operation is started. This operation is implicitly in-place.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__collective__api_1ga5b70cb9c7e6ba209baf5b72f387a08d7","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const void *","declname":"sendbuff","direction":"in","parameterdescription":"Data array to copy (if root). May be NULL for other ranks"},{"type":"void *","declname":"recvbuff","direction":"in","parameterdescription":"Data array to store received array"},{"type":"size_t","declname":"count","direction":"in","parameterdescription":"Number of elements in data buffer"},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"int","declname":"root","direction":"in","parameterdescription":"Rank of broadcast root"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t ncclBroadcast","argsstring":"(const void *sendbuff, void *recvbuff, size_t count, ncclDataType_t datatype, int root, ncclComm_t comm, hipStream_t stream)","name":"ncclBroadcast","briefdescription":"Broadcast.","detaileddescription":"Copies values from on to on all devices. root* is the rank (not the HIP device) where data resides before the operation is started. sendbuff* may be NULL on ranks other than . In-place operation will happen if == .","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__collective__api_1ga30da781a49c7935ce3cb0156ed57b438","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const void *","declname":"sendbuff","direction":"in","parameterdescription":"Input data array to reduce"},{"type":"void *","declname":"recvbuff","direction":"out","parameterdescription":"Data array to store reduced result array"},{"type":"size_t","declname":"count","direction":"in","parameterdescription":"Number of elements in data buffer"},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"ncclRedOp_t","declname":"op","direction":"in","parameterdescription":"Reduction operator"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t ncclAllReduce","argsstring":"(const void *sendbuff, void *recvbuff, size_t count, ncclDataType_t datatype, ncclRedOp_t op, ncclComm_t comm, hipStream_t stream)","name":"ncclAllReduce","briefdescription":"All-Reduce.","detaileddescription":"Reduces data arrays of length in using operation, and leaves identical copies of result on each . In-place operation will happen if sendbuff == recvbuff.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__collective__api_1ga4cea2983c15d34a0531e549b06790a3b","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const void *","declname":"sendbuff","direction":"in","parameterdescription":"Input data array to reduce"},{"type":"void *","declname":"recvbuff","direction":"out","parameterdescription":"Data array to store reduced result subarray"},{"type":"size_t","declname":"recvcount","direction":"in","parameterdescription":"Number of elements each rank receives"},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"ncclRedOp_t","declname":"op","direction":"in","parameterdescription":"Reduction operator"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t ncclReduceScatter","argsstring":"(const void *sendbuff, void *recvbuff, size_t recvcount, ncclDataType_t datatype, ncclRedOp_t op, ncclComm_t comm, hipStream_t stream)","name":"ncclReduceScatter","briefdescription":"Reduce-Scatter.","detaileddescription":"Reduces data in using operation and leaves reduced result scattered over the devices so that on rank i will contain the i-th block of the result. Assumes sendcount is equal to nranks*recvcount, which means that should have a size of at least nranks*recvcount elements. In-place operations will happen if recvbuff == sendbuff + rank * recvcount.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__collective__api_1gae076e5ed96c575703eb27c183f47c148","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const void *","declname":"sendbuff","direction":"in","parameterdescription":"Input data array to send"},{"type":"void *","declname":"recvbuff","direction":"out","parameterdescription":"Data array to store the gathered result"},{"type":"size_t","declname":"sendcount","direction":"in","parameterdescription":"Number of elements each rank sends"},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t ncclAllGather","argsstring":"(const void *sendbuff, void *recvbuff, size_t sendcount, ncclDataType_t datatype, ncclComm_t comm, hipStream_t stream)","name":"ncclAllGather","briefdescription":"All-Gather.","detaileddescription":"Each device gathers values from other GPUs into , receiving data from rank i at offset i*sendcount. Assumes recvcount is equal to nranks*sendcount, which means that recvbuff should have a size of at least nranks*sendcount elements. In-place operations will happen if sendbuff == recvbuff + rank * sendcount.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__collective__api_1gaaa66205aebc317e447cc596425edaa1e","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const void *","declname":"sendbuff","direction":"in","parameterdescription":"Data array to send"},{"type":"size_t","declname":"count","direction":"in","parameterdescription":"Number of elements to send"},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"int","declname":"peer","direction":"in","parameterdescription":"Peer rank to send to"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t ncclSend","argsstring":"(const void *sendbuff, size_t count, ncclDataType_t datatype, int peer, ncclComm_t comm, hipStream_t stream)","name":"ncclSend","briefdescription":"Send.","detaileddescription":"Send data from to rank . Rank needs to call ncclRecv with the same and the same as this rank. This operation is blocking for the GPU. If multiple ncclSend and ncclRecv operations need to progress concurrently to complete, they must be fused within a ncclGroupStart \/ ncclGroupEnd section.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__collective__api_1gab97b538f4b6f472e0b9edc12bb06f8f6","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"void *","declname":"recvbuff","direction":"out","parameterdescription":"Data array to receive"},{"type":"size_t","declname":"count","direction":"in","parameterdescription":"Number of elements to receive"},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"int","declname":"peer","direction":"in","parameterdescription":"Peer rank to send to"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t ncclRecv","argsstring":"(void *recvbuff, size_t count, ncclDataType_t datatype, int peer, ncclComm_t comm, hipStream_t stream)","name":"ncclRecv","briefdescription":"Receive.","detaileddescription":"Receive data from rank into . Rank needs to call ncclSend with the same datatype and the same count as this rank. This operation is blocking for the GPU. If multiple ncclSend and ncclRecv operations need to progress concurrently to complete, they must be fused within a ncclGroupStart\/ ncclGroupEnd section.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__collective__api_1ga0eaed41aeaafc5bcc7d08328ea03a06b","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const void *","declname":"sendbuff","direction":"in","parameterdescription":"Data array to send"},{"type":"void *","declname":"recvbuff","direction":"out","parameterdescription":"Data array to receive into on root."},{"type":"size_t","declname":"sendcount","direction":"in","parameterdescription":"Number of elements to send per rank"},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"int","declname":"root","direction":"in","parameterdescription":"Rank that receives data from all other ranks"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t ncclGather","argsstring":"(const void *sendbuff, void *recvbuff, size_t sendcount, ncclDataType_t datatype, int root, ncclComm_t comm, hipStream_t stream)","name":"ncclGather","briefdescription":"Gather.","detaileddescription":"Root device gathers values from other GPUs into , receiving data from rank i at offset i*sendcount. Assumes recvcount is equal to nranks*sendcount, which means that should have a size of at least nranks*sendcount elements. In-place operations will happen if sendbuff == recvbuff + rank * sendcount. recvbuff* may be NULL on ranks other than .","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__collective__api_1ga6ff13983986f2193eac841bb856c0857","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const void *","declname":"sendbuff","direction":"in","parameterdescription":"Data array to send (on root rank). May be NULL on other ranks."},{"type":"void *","declname":"recvbuff","direction":"out","parameterdescription":"Data array to receive partial subarray into"},{"type":"size_t","declname":"recvcount","direction":"in","parameterdescription":"Number of elements to receive per rank"},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"int","declname":"root","direction":"in","parameterdescription":"Rank that scatters data to all other ranks"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t ncclScatter","argsstring":"(const void *sendbuff, void *recvbuff, size_t recvcount, ncclDataType_t datatype, int root, ncclComm_t comm, hipStream_t stream)","name":"ncclScatter","briefdescription":"Scatter.","detaileddescription":"Scattered over the devices so that recvbuff on rank i will contain the i-th block of the data on root. Assumes sendcount is equal to nranks*recvcount, which means that should have a size of at least nranks*recvcount elements. In-place operations will happen if recvbuff == sendbuff + rank * recvcount.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__collective__api_1ga667131e427e7159bcfb16c2bf8287dfd","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const void *","declname":"sendbuff","direction":"in","parameterdescription":"Data array to send (contains blocks for each other rank)"},{"type":"void *","declname":"recvbuff","direction":"out","parameterdescription":"Data array to receive (contains blocks from each other rank)"},{"type":"size_t","declname":"count","direction":"in","parameterdescription":"Number of elements to send between each pair of ranks"},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t ncclAllToAll","argsstring":"(const void *sendbuff, void *recvbuff, size_t count, ncclDataType_t datatype, ncclComm_t comm, hipStream_t stream)","name":"ncclAllToAll","briefdescription":"All-To-All.","detaileddescription":"Device (i) send (j)th block of data to device (j) and be placed as (i)th block. Each block for sending\/receiving has elements, which means that and should have a size of nranks*count elements. In-place operation is NOT supported. It is the user's responsibility to ensure that sendbuff and recvbuff are distinct.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__collective__api_1ga191cbb7b99a5b28ff85a10c93082cd8b","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const void *","declname":"sendbuff","direction":"in","parameterdescription":"Data array to send (contains blocks for each other rank)"},{"type":"const size_t","declname":"sendcounts","direction":"in","parameterdescription":"Array containing number of elements to send to each participating rank"},{"type":"const size_t","declname":"sdispls","direction":"in","parameterdescription":"Array of offsets into sendbuff for each participating rank"},{"type":"void *","declname":"recvbuff","direction":"out","parameterdescription":"Data array to receive (contains blocks from each other rank)"},{"type":"const size_t","declname":"recvcounts","direction":"in","parameterdescription":"Array containing number of elements to receive from each participating rank"},{"type":"const size_t","declname":"rdispls","direction":"in","parameterdescription":"Array of offsets into recvbuff for each participating rank"},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t ncclAllToAllv","argsstring":"(const void *sendbuff, const size_t sendcounts[], const size_t sdispls[], void *recvbuff, const size_t recvcounts[], const size_t rdispls[], ncclDataType_t datatype, ncclComm_t comm, hipStream_t stream)","name":"ncclAllToAllv","briefdescription":"All-To-Allv.","detaileddescription":"Device (i) sends sendcounts[j] of data from offset sdispls[j] to device (j). At the same time, device (i) receives recvcounts[j] of data from device (j) to be placed at rdispls[j]. sendcounts, sdispls, recvcounts and rdispls are all measured in the units of datatype, not bytes. In-place operation will happen if sendbuff == recvbuff.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__msccl__api_1gafc8446f6990399459ea17c3844cb53fd","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const char *","declname":"mscclAlgoFilePath","direction":"in","parameterdescription":"Path to MSCCL algorithm file"},{"type":"mscclAlgoHandle_t *","declname":"mscclAlgoHandle","direction":"out","parameterdescription":"Returned handle to MSCCL algorithm"},{"type":"int","declname":"rank","direction":"in","parameterdescription":"Current rank"}],"type":"ncclResult_t","definition":"ncclResult_t mscclLoadAlgo","argsstring":"(const char *mscclAlgoFilePath, mscclAlgoHandle_t *mscclAlgoHandle, int rank)","name":"mscclLoadAlgo","briefdescription":"MSCCL Load Algorithm.","detaileddescription":"Load MSCCL algorithm file specified in mscclAlgoFilePath and return its handle via mscclAlgoHandle. This API is expected to be called by MSCCL scheduler instead of end users.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__msccl__api_1ga59c37e39ac3733bef3c84d4b2f1243a4","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const void *","declname":"sendBuff","direction":"in","parameterdescription":"Data array to send"},{"type":"const size_t","declname":"sendCounts","direction":"in","parameterdescription":"Array containing number of elements to send to each participating rank"},{"type":"const size_t","declname":"sDisPls","direction":"in","parameterdescription":"Array of offsets into sendbuff for each participating rank"},{"type":"void *","declname":"recvBuff","direction":"out","parameterdescription":"Data array to receive"},{"type":"const size_t","declname":"recvCounts","direction":"in","parameterdescription":"Array containing number of elements to receive from each participating rank"},{"type":"const size_t","declname":"rDisPls","direction":"in","parameterdescription":"Array of offsets into recvbuff for each participating rank"},{"type":"size_t","declname":"count","direction":"in","parameterdescription":"Number of elements"},{"type":"ncclDataType_t","declname":"dataType","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"int","declname":"root","direction":"in","parameterdescription":"Root rank index"},{"type":"int","declname":"peer","direction":"in","parameterdescription":"Peer rank index"},{"type":"ncclRedOp_t","declname":"op","direction":"in","parameterdescription":"Reduction operator"},{"type":"mscclAlgoHandle_t","declname":"mscclAlgoHandle","direction":"in","parameterdescription":"Handle to MSCCL algorithm"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t mscclRunAlgo","argsstring":"(const void *sendBuff, const size_t sendCounts[], const size_t sDisPls[], void *recvBuff, const size_t recvCounts[], const size_t rDisPls[], size_t count, ncclDataType_t dataType, int root, int peer, ncclRedOp_t op, mscclAlgoHandle_t mscclAlgoHandle, ncclComm_t comm, hipStream_t stream)","name":"mscclRunAlgo","briefdescription":"MSCCL Run Algorithm.","detaileddescription":"Run MSCCL algorithm specified by mscclAlgoHandle. The parameter list merges all possible parameters required by different operations as this is a general-purposed API. This API is expected to be called by MSCCL scheduler instead of end users.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__msccl__api_1gafdb450531b5feeb3df5649e6bbef794e","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"mscclAlgoHandle_t","declname":"mscclAlgoHandle","direction":"in","parameterdescription":"Handle to MSCCL algorithm to unload"}],"type":"ncclResult_t","definition":"ncclResult_t mscclUnloadAlgo","argsstring":"(mscclAlgoHandle_t mscclAlgoHandle)","name":"mscclUnloadAlgo","briefdescription":"MSCCL Unload Algorithm.","detaileddescription":"Unload MSCCL algorithm previous loaded using its handle. This API is expected to be called by MSCCL scheduler instead of end users.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__group__api_1gaf81ec09dc19a44137a67958e5e209f2b","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[],"type":"ncclResult_t","definition":"ncclResult_t ncclGroupStart","argsstring":"()","name":"ncclGroupStart","briefdescription":"Group Start.","detaileddescription":"Start a group call. All calls to RCCL until ncclGroupEnd will be fused into a single RCCL operation. Nothing will be started on the HIP stream until ncclGroupEnd.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__group__api_1gafdeb850e3e594843faf8a98e8e86ec0c","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[],"type":"ncclResult_t","definition":"ncclResult_t ncclGroupEnd","argsstring":"()","name":"ncclGroupEnd","briefdescription":"Group End.","detaileddescription":"End a group call. Start a fused RCCL operation consisting of all calls since ncclGroupStart. Operations on the HIP stream depending on the RCCL operations need to be called after ncclGroupEnd.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."}]}
{"id":"group__rccl__result__code","kind":"group","language":null,"prot":null,"compoundname":"rccl_result_code","title":"Result Codes","briefdescription":"","detaileddescription":"The various result codes that RCCL API calls may return","includes":[],"memberdefs":[{"kind":"enum","id":"group__rccl__result__code_1ga55fb03de49ceafd58b85851c12fd2f9b","prot":"public","static":"no","strong":"no","type":null,"name":"ncclResult_t","briefdescription":"Result type.","detaileddescription":"Return codes aside from ncclSuccess indicate that a call has failed","inbodydescription":null,"initializer":null,"enumvalue":[{"id":"group__rccl__result__code_1gga55fb03de49ceafd58b85851c12fd2f9bac0fdf720be5323a352e2f7d326a95e0c","prot":"public","name":"ncclSuccess","initializer":"= 0","briefdescription":"","detaileddescription":"No error"},{"id":"group__rccl__result__code_1gga55fb03de49ceafd58b85851c12fd2f9baf558f3a7d72c4a1afe21713f21b5462b","prot":"public","name":"ncclUnhandledCudaError","initializer":"= 1","briefdescription":"","detaileddescription":"Unhandled HIP error"},{"id":"group__rccl__result__code_1gga55fb03de49ceafd58b85851c12fd2f9ba6c5fc68e72a0bf32b63896dae693aabd","prot":"public","name":"ncclSystemError","initializer":"= 2","briefdescription":"","detaileddescription":"Unhandled system error"},{"id":"group__rccl__result__code_1gga55fb03de49ceafd58b85851c12fd2f9ba848f01c9a93891fd6cb1f75f75a4225d","prot":"public","name":"ncclInternalError","initializer":"= 3","briefdescription":"","detaileddescription":"Internal Error - Please report to RCCL developers"},{"id":"group__rccl__result__code_1gga55fb03de49ceafd58b85851c12fd2f9baf080ab7ddae4277af1c1ed8ad86c0064","prot":"public","name":"ncclInvalidArgument","initializer":"= 4","briefdescription":"","detaileddescription":"Invalid argument"},{"id":"group__rccl__result__code_1gga55fb03de49ceafd58b85851c12fd2f9ba39ae1f6eaeeece5db98c0e4f16792dd9","prot":"public","name":"ncclInvalidUsage","initializer":"= 5","briefdescription":"","detaileddescription":"Invalid usage"},{"id":"group__rccl__result__code_1gga55fb03de49ceafd58b85851c12fd2f9ba54943f2d63afabd25967e6af1c7c695e","prot":"public","name":"ncclRemoteError","initializer":"= 6","briefdescription":"","detaileddescription":"Remote process exited or there was a network error"},{"id":"group__rccl__result__code_1gga55fb03de49ceafd58b85851c12fd2f9ba49ac32824d76708227cce42a79ad5451","prot":"public","name":"ncclInProgress","initializer":"= 7","briefdescription":"","detaileddescription":"RCCL operation in progress"},{"id":"group__rccl__result__code_1gga55fb03de49ceafd58b85851c12fd2f9ba4a31f5fab974f5bc93c5fd83628ed589","prot":"public","name":"ncclNumResults","initializer":"= 8","briefdescription":"","detaileddescription":"Number of result types"}]}]}
{"id":"group__rccl__config__type","kind":"group","language":null,"prot":null,"compoundname":"rccl_config_type","title":"Communicator Configuration","briefdescription":"","detaileddescription":"Structure that allows for customizing Communicator behavior via ncclCommInitRankConfig","includes":[],"memberdefs":[{"kind":"define","id":"group__rccl__config__type_1ga01bcf2fc58fdeb3d705c375a9e8e6641","prot":"public","static":"no","name":"NCCL_CONFIG_INITIALIZER","briefdescription":null,"detaileddescription":null,"inbodydescription":null,"initializer":"{ \\ sizeof(ncclConfig_t), \/* size *\/ \\ 0xcafebeef, \/* magic *\/ \\ NCCL_VERSION(NCCL_MAJOR, NCCL_MINOR, NCCL_PATCH), \/* version *\/ \\ NCCL_CONFIG_UNDEF_INT, \/* blocking *\/ \\ NCCL_CONFIG_UNDEF_INT, \/* cgaClusterSize *\/ \\ NCCL_CONFIG_UNDEF_INT, \/* minCTAs *\/ \\ NCCL_CONFIG_UNDEF_INT, \/* maxCTAs *\/ \\ NCCL_CONFIG_UNDEF_PTR, \/* netName *\/ \\ NCCL_CONFIG_UNDEF_INT \/* splitShare *\/ \\ }"}]}
{"id":"group__rccl__api__version","kind":"group","language":null,"prot":null,"compoundname":"rccl_api_version","title":"Version Information","briefdescription":"","detaileddescription":"API call that returns RCCL version","includes":[],"memberdefs":[{"kind":"function","id":"group__rccl__api__version_1gaa94bf928cefe8d1a11a92ec68c640d0d","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"int *","declname":"version","direction":"out","parameterdescription":"Pointer to where version will be stored"}],"type":"ncclResult_t","definition":"ncclResult_t ncclGetVersion","argsstring":"(int *version)","name":"ncclGetVersion","briefdescription":"Return the RCCL_VERSION_CODE of RCCL in the supplied integer.","detaileddescription":"This integer is coded with the MAJOR, MINOR and PATCH level of RCCL.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."}]}
{"id":"group__rccl__api__communicator","kind":"group","language":null,"prot":null,"compoundname":"rccl_api_communicator","title":"Communicator Initialization\/Destruction","briefdescription":"","detaileddescription":"API calls that operate on communicators. Communicators objects are used to launch collective communication operations. Unique ranks between 0 and N-1 must be assigned to each HIP device participating in the same Communicator. Using the same HIP device for multiple ranks of the same Communicator is not supported at this time.","includes":[],"memberdefs":[{"kind":"function","id":"group__rccl__api__communicator_1ga53d41b0397871975f6c19bed19f35a88","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclUniqueId *","declname":"uniqueId","direction":"out","parameterdescription":"Pointer to where uniqueId will be stored"}],"type":"ncclResult_t","definition":"ncclResult_t ncclGetUniqueId","argsstring":"(ncclUniqueId *uniqueId)","name":"ncclGetUniqueId","briefdescription":"Generates an ID for ncclCommInitRank.","detaileddescription":"Generates an ID to be used in ncclCommInitRank. ncclGetUniqueId should be called once by a single rank and the ID should be distributed to all ranks in the communicator before using it as a parameter for ncclCommInitRank.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__api__communicator_1ga7f5e9012f8ce9bbb87c19e0fd9030c21","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclComm_t *","declname":"comm","direction":"out","parameterdescription":"Pointer to created communicator"},{"type":"int","declname":"nranks","direction":"in","parameterdescription":"Total number of ranks participating in this communicator"},{"type":"ncclUniqueId","declname":"commId","direction":"in","parameterdescription":"UniqueId required for initialization"},{"type":"int","declname":"rank","direction":"in","parameterdescription":"Current rank to create communicator for. [0 to nranks-1]"},{"type":"ncclConfig_t *","declname":"config","direction":"in","parameterdescription":"Pointer to communicator configuration"}],"type":"ncclResult_t","definition":"ncclResult_t ncclCommInitRankConfig","argsstring":"(ncclComm_t *comm, int nranks, ncclUniqueId commId, int rank, ncclConfig_t *config)","name":"ncclCommInitRankConfig","briefdescription":"Create a new communicator with config.","detaileddescription":"Create a new communicator (multi thread\/process version) with a configuration set by users. See for more details. Each rank is associated to a CUDA device, which has to be set before calling ncclCommInitRank.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__api__communicator_1ga23fea6998061aadac1bdde55648ca40e","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclComm_t *","declname":"comm","direction":"out","parameterdescription":"Pointer to created communicator"},{"type":"int","declname":"nranks","direction":"in","parameterdescription":"Total number of ranks participating in this communicator"},{"type":"ncclUniqueId","declname":"commId","direction":"in","parameterdescription":"UniqueId required for initialization"},{"type":"int","declname":"rank","direction":"in","parameterdescription":"Current rank to create communicator for"}],"type":"ncclResult_t","definition":"ncclResult_t ncclCommInitRank","argsstring":"(ncclComm_t *comm, int nranks, ncclUniqueId commId, int rank)","name":"ncclCommInitRank","briefdescription":"Creates a new communicator (multi thread\/process version).","detaileddescription":"Rank must be between 0 and nranks-1 and unique within a communicator clique. Each rank is associated to a CUDA device, which has to be set before calling ncclCommInitRank. ncclCommInitRank implicitly syncronizes with other ranks, so it must be called by different threads\/processes or use ncclGroupStart\/ncclGroupEnd.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__api__communicator_1gae2b97ef85192c88ce8f2d5cf309855a2","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclComm_t *","declname":"comm","direction":"out","parameterdescription":"Pointer to array of created communicators"},{"type":"int","declname":"ndev","direction":"in","parameterdescription":"Total number of ranks participating in this communicator"},{"type":"const int *","declname":"devlist","direction":"in","parameterdescription":"Array of GPU device indices to create for"}],"type":"ncclResult_t","definition":"ncclResult_t ncclCommInitAll","argsstring":"(ncclComm_t *comm, int ndev, const int *devlist)","name":"ncclCommInitAll","briefdescription":"Creates a clique of communicators (single process version).","detaileddescription":"This is a convenience function to create a single-process communicator clique. Returns an array of ndev newly initialized communicators in comm. comm should be pre-allocated with size at least ndev*sizeof(ncclComm_t). If devlist is NULL, the first ndev HIP devices are used. Order of devlist defines user-order of processors within the communicator.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__api__communicator_1ga2a3f3b807ec33d97618d0d7ac0eb2a91","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator to finalize"}],"type":"ncclResult_t","definition":"ncclResult_t ncclCommFinalize","argsstring":"(ncclComm_t comm)","name":"ncclCommFinalize","briefdescription":"Finalize a communicator.","detaileddescription":"ncclCommFinalize flushes all issued communications and marks communicator state as ncclInProgress. The state will change to ncclSuccess when the communicator is globally quiescent and related resources are freed; then, calling ncclCommDestroy can locally free the rest of the resources (e.g. communicator itself) without blocking.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__api__communicator_1ga333fba6c01bd6fe2a285e5a7929fcd02","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator to destroy"}],"type":"ncclResult_t","definition":"ncclResult_t ncclCommDestroy","argsstring":"(ncclComm_t comm)","name":"ncclCommDestroy","briefdescription":"Frees local resources associated with communicator object.","detaileddescription":"Destroy all local resources associated with the passed in communicator object","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__api__communicator_1ga5fa333fe131f53ef76216d8a95b05a58","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator to abort and destroy"}],"type":"ncclResult_t","definition":"ncclResult_t ncclCommAbort","argsstring":"(ncclComm_t comm)","name":"ncclCommAbort","briefdescription":"Abort any in-progress calls and destroy the communicator object.","detaileddescription":"Frees resources associated with communicator object and aborts any operations that might still be running on the device.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__api__communicator_1gad370ee2fde1d6f518ab289c6cdbe8e9d","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Original communicator object for this rank"},{"type":"int","declname":"color","direction":"in","parameterdescription":"Color to assign this rank"},{"type":"int","declname":"key","direction":"in","parameterdescription":"Key used to order ranks within the same new communicator"},{"type":"ncclComm_t *","declname":"newcomm","direction":"out","parameterdescription":"Pointer to new communicator"},{"type":"ncclConfig_t *","declname":"config","direction":"in","parameterdescription":"Config file for new communicator. May be NULL to inherit from comm"}],"type":"ncclResult_t","definition":"ncclResult_t ncclCommSplit","argsstring":"(ncclComm_t comm, int color, int key, ncclComm_t *newcomm, ncclConfig_t *config)","name":"ncclCommSplit","briefdescription":"Create one or more communicators from an existing one.","detaileddescription":"Creates one or more communicators from an existing one. Ranks with the same color will end up in the same communicator. Within the new communicator, key will be used to order ranks. NCCL_SPLIT_NOCOLOR as color will indicate the rank will not be part of any group and will therefore return a NULL communicator. If config is NULL, the new communicator will inherit the original communicator's configuration","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."}]}
{"id":"group__rccl__api__errcheck","kind":"group","language":null,"prot":null,"compoundname":"rccl_api_errcheck","title":"Error Checking Calls","briefdescription":"","detaileddescription":"API calls that check for errors","includes":[],"memberdefs":[{"kind":"function","id":"group__rccl__api__errcheck_1gabd1cc4f6df988e713f23b549bcb95b56","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclResult_t","declname":"result","direction":"in","parameterdescription":"Result code to get description for"}],"type":"const char *","definition":"const char* ncclGetErrorString","argsstring":"(ncclResult_t result)","name":"ncclGetErrorString","briefdescription":"Returns a string for each result code.","detaileddescription":"Returns a human-readable string describing the given result code.","inbodydescription":null,"initializer":null,"returns":"String containing description of result code."},{"kind":"function","id":"group__rccl__api__errcheck_1ga91fc7cb1d79c972fcbe97d32e9172476","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"is currently unused and can be set to NULL"}],"type":"const char *","definition":"const char* ncclGetLastError","argsstring":"(ncclComm_t comm)","name":"ncclGetLastError","briefdescription":"Returns mesage on last result that occured.","detaileddescription":"Returns a human-readable message of the last error that occurred.","inbodydescription":null,"initializer":null,"returns":"String containing the last result"},{"kind":"function","id":"group__rccl__api__errcheck_1gad7e3ece2064eafde9f01221674f872ac","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator to query"},{"type":"ncclResult_t *","declname":"asyncError","direction":"out","parameterdescription":"Pointer to where result code will be stored"}],"type":"ncclResult_t","definition":"ncclResult_t ncclCommGetAsyncError","argsstring":"(ncclComm_t comm, ncclResult_t *asyncError)","name":"ncclCommGetAsyncError","briefdescription":"Checks whether the comm has encountered any asynchronous errors.","detaileddescription":"Query whether the provided communicator has encountered any asynchronous errors","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."}]}
{"id":"group__rccl__api__comminfo","kind":"group","language":null,"prot":null,"compoundname":"rccl_api_comminfo","title":"Communicator Information","briefdescription":"","detaileddescription":"API calls that query communicator information","includes":[],"memberdefs":[{"kind":"function","id":"group__rccl__api__comminfo_1gad04d727a6eb4da7c8da5ec90f771b22f","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator to query"},{"type":"int *","declname":"count","direction":"out","parameterdescription":"Pointer to where number of ranks will be stored"}],"type":"ncclResult_t","definition":"ncclResult_t ncclCommCount","argsstring":"(const ncclComm_t comm, int *count)","name":"ncclCommCount","briefdescription":"Gets the number of ranks in the communicator clique.","detaileddescription":"Returns the number of ranks in the communicator clique (as set during initialization)","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__api__comminfo_1ga61c5f1a88f7cabc3c3e1017c424387b9","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator to query"},{"type":"int *","declname":"device","direction":"out","parameterdescription":"Pointer to where the associated ROCm device index will be stored"}],"type":"ncclResult_t","definition":"ncclResult_t ncclCommCuDevice","argsstring":"(const ncclComm_t comm, int *device)","name":"ncclCommCuDevice","briefdescription":"Get the ROCm device index associated with a communicator.","detaileddescription":"Returns the ROCm device number associated with the provided communicator.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__api__comminfo_1ga8f7c6cbb83b9eb549103012829f5ab9f","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator to query"},{"type":"int *","declname":"rank","direction":"out","parameterdescription":"Pointer to where the associated rank will be stored"}],"type":"ncclResult_t","definition":"ncclResult_t ncclCommUserRank","argsstring":"(const ncclComm_t comm, int *rank)","name":"ncclCommUserRank","briefdescription":"Get the rank associated with a communicator.","detaileddescription":"Returns the user-ordered \"rank\" associated with the provided communicator.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."}]}
{"id":"group__rccl__api__enumerations","kind":"group","language":null,"prot":null,"compoundname":"rccl_api_enumerations","title":"API Enumerations","briefdescription":"","detaileddescription":"Enumerations used by collective communication calls","includes":[],"memberdefs":[{"kind":"enum","id":"group__rccl__api__enumerations_1ga87c10957f4ed69dac2782c16553587d2","prot":"public","static":"no","strong":"no","type":null,"name":"ncclRedOp_dummy_t","briefdescription":"Dummy reduction enumeration.","detaileddescription":"Dummy reduction enumeration used to determine value for ncclMaxRedOp","inbodydescription":null,"initializer":null,"enumvalue":[{"id":"group__rccl__api__enumerations_1gga87c10957f4ed69dac2782c16553587d2a96255037fda3c88bbc9dc43f041d2537","prot":"public","name":"ncclNumOps_dummy","initializer":"= 5","briefdescription":"","detaileddescription":""}]},{"kind":"enum","id":"group__rccl__api__enumerations_1ga921726a1c391fbb4ecc6e9cf00294524","prot":"public","static":"no","strong":"no","type":null,"name":"ncclRedOp_t","briefdescription":"Reduction operation selector.","detaileddescription":"Enumeration used to specify the various reduction operations ncclNumOps is the number of built-in ncclRedOp_t values and serves as the least possible value for dynamic ncclRedOp_t values constructed by ncclRedOpCreate functions.ncclMaxRedOp is the largest valid value for ncclRedOp_t and is defined to be the largest signed value (since compilers are permitted to use signed enums) that won't grow sizeof(ncclRedOp_t) when compared to previous RCCL versions to maintain ABI compatibility.","inbodydescription":null,"initializer":null,"enumvalue":[{"id":"group__rccl__api__enumerations_1gga921726a1c391fbb4ecc6e9cf00294524a344420f29fe77f9124aa46de1447a43e","prot":"public","name":"ncclSum","initializer":"= 0","briefdescription":"","detaileddescription":"Sum"},{"id":"group__rccl__api__enumerations_1gga921726a1c391fbb4ecc6e9cf00294524aed6b2548a983f976c9b6751c66e525e1","prot":"public","name":"ncclProd","initializer":"= 1","briefdescription":"","detaileddescription":"Product"},{"id":"group__rccl__api__enumerations_1gga921726a1c391fbb4ecc6e9cf00294524aff6a64c28091cc6123a68a328aa518e9","prot":"public","name":"ncclMax","initializer":"= 2","briefdescription":"","detaileddescription":"Max"},{"id":"group__rccl__api__enumerations_1gga921726a1c391fbb4ecc6e9cf00294524a1451e8ae4b66a096d7d7f40ea8efb3d1","prot":"public","name":"ncclMin","initializer":"= 3","briefdescription":"","detaileddescription":"Min"},{"id":"group__rccl__api__enumerations_1gga921726a1c391fbb4ecc6e9cf00294524aff95c7e0300edaaed8d85111f06440b1","prot":"public","name":"ncclAvg","initializer":"= 4","briefdescription":"","detaileddescription":"Average"},{"id":"group__rccl__api__enumerations_1gga921726a1c391fbb4ecc6e9cf00294524a1924e1d9d29535ce44bbe5d26034ca5a","prot":"public","name":"ncclNumOps","initializer":"= 5","briefdescription":"","detaileddescription":"Number of built-in reduction ops"},{"id":"group__rccl__api__enumerations_1gga921726a1c391fbb4ecc6e9cf00294524a595f3f9fac30ac16b0700e152e73aba0","prot":"public","name":"ncclMaxRedOp","initializer":"= 0x7fffffff>>(32-8*sizeof(ncclRedOp_dummy_t))","briefdescription":"","detaileddescription":"Largest value for ncclRedOp_t"}]},{"kind":"enum","id":"group__rccl__api__enumerations_1ga9a37adf1ce63a5edd2f7eda6305b2b9b","prot":"public","static":"no","strong":"no","type":null,"name":"ncclDataType_t","briefdescription":"Data types.","detaileddescription":"Enumeration of the various supported datatype","inbodydescription":null,"initializer":null,"enumvalue":[{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9ba85071680188efee7900241d542e77f06","prot":"public","name":"ncclInt8","initializer":"= 0","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9baba531d24a08b8f7264cf91541cdfff3f","prot":"public","name":"ncclChar","initializer":"= 0","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9bad3d205d5e216795c7fe7d574fb3c72b4","prot":"public","name":"ncclUint8","initializer":"= 1","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9ba26f2406ddd8f3b8e923df2d0302a6a1b","prot":"public","name":"ncclInt32","initializer":"= 2","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9babf08532f223398863c9b168e6b08e7be","prot":"public","name":"ncclInt","initializer":"= 2","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9ba749fbbbfe3992027638ab02e94f13694","prot":"public","name":"ncclUint32","initializer":"= 3","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9bae439a1da80920fdda1b18313eea95507","prot":"public","name":"ncclInt64","initializer":"= 4","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9bac8ba680aba07abcc1c5d18fea2294517","prot":"public","name":"ncclUint64","initializer":"= 5","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9bae6bfae9dbcb7ee80a3a03bc8579acdbe","prot":"public","name":"ncclFloat16","initializer":"= 6","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9ba04d86767f185410a447bd4ebabee287d","prot":"public","name":"ncclHalf","initializer":"= 6","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9ba9ff7882c7811330dcd33cef5df2cfac2","prot":"public","name":"ncclFloat32","initializer":"= 7","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9bab6497c7b7df34db5e51d8e3e146bd266","prot":"public","name":"ncclFloat","initializer":"= 7","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9ba0368d171ce5e7e9324169cbc76ae1200","prot":"public","name":"ncclFloat64","initializer":"= 8","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9ba890cf5618feba1d76287c710c84b2f12","prot":"public","name":"ncclDouble","initializer":"= 8","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9baae6bb61a7c162f64cd8ea078e30890fa","prot":"public","name":"ncclBfloat16","initializer":"= 9","briefdescription":"","detaileddescription":""},{"id":"group__rccl__api__enumerations_1gga9a37adf1ce63a5edd2f7eda6305b2b9ba6ea571a3fe475a98c7b36ffe95d1c37d","prot":"public","name":"ncclNumTypes","initializer":"= 10","briefdescription":"","detaileddescription":""}]}]}
{"id":"group__rccl__api__custom__redop","kind":"group","language":null,"prot":null,"compoundname":"rccl_api_custom_redop","title":"Custom Reduction Operator","briefdescription":"","detaileddescription":"API calls relating to creation\/destroying custom reduction operator that pre-multiplies local source arrays prior to reduction","includes":[],"memberdefs":[{"kind":"enum","id":"group__rccl__api__custom__redop_1ga0d7ee97426bc0eb7020cb3c9ebef6ea7","prot":"public","static":"no","strong":"no","type":null,"name":"ncclScalarResidence_t","briefdescription":"Location and dereferencing logic for scalar arguments.","detaileddescription":"Enumeration specifying memory location of the scalar argument. Based on where the value is stored, the argument will be dereferenced either while the collective is running (if in device memory), or before the ncclRedOpCreate() function returns (if in host memory).","inbodydescription":null,"initializer":null,"enumvalue":[{"id":"group__rccl__api__custom__redop_1gga0d7ee97426bc0eb7020cb3c9ebef6ea7ae65101c0646f7a5de231132aa4ef30d3","prot":"public","name":"ncclScalarDevice","initializer":"= 0","briefdescription":"","detaileddescription":"Scalar is in device-visible memory"},{"id":"group__rccl__api__custom__redop_1gga0d7ee97426bc0eb7020cb3c9ebef6ea7ad01760269a6bc2661aa9fb7f52568228","prot":"public","name":"ncclScalarHostImmediate","initializer":"= 1","briefdescription":"","detaileddescription":"Scalar is in host-visible memory"}]},{"kind":"function","id":"group__rccl__api__custom__redop_1ga35e2028c6f6c40ae4aea90a5076eabfc","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclRedOp_t *","declname":"op","direction":"out","parameterdescription":"Pointer to where newly created custom reduction operator is to be stored"},{"type":"void *","declname":"scalar","direction":"in","parameterdescription":"Pointer to scalar value."},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Scalar value datatype"},{"type":"ncclScalarResidence_t","declname":"residence","direction":"in","parameterdescription":"Memory type of the scalar value"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator to associate with this custom reduction operator"}],"type":"ncclResult_t","definition":"ncclResult_t ncclRedOpCreatePreMulSum","argsstring":"(ncclRedOp_t *op, void *scalar, ncclDataType_t datatype, ncclScalarResidence_t residence, ncclComm_t comm)","name":"ncclRedOpCreatePreMulSum","briefdescription":"Create a custom pre-multiplier reduction operator.","detaileddescription":"Creates a new reduction operator which pre-multiplies input values by a given scalar locally before reducing them with peer values via summation. For use only with collectives launched against and . The residence* argument indicates how\/when the memory pointed to by will be dereferenced. Upon return, the newly created operator's handle is stored in .","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__api__custom__redop_1gad3ed8c2e917e71c3dc4918c1f2641aac","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"ncclRedOp_t","declname":"op","direction":"in","parameterdescription":"Custom reduction operator is to be destroyed"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator associated with this reduction operator"}],"type":"ncclResult_t","definition":"ncclResult_t ncclRedOpDestroy","argsstring":"(ncclRedOp_t op, ncclComm_t comm)","name":"ncclRedOpDestroy","briefdescription":"Destroy custom reduction operator.","detaileddescription":"Destroys the reduction operator . The operator must have been created by ncclRedOpCreatePreMul with the matching communicator . An operator may be destroyed as soon as the last RCCL function which is given that operator returns.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."}]}
{"id":"group__rccl__collective__api","kind":"group","language":null,"prot":null,"compoundname":"rccl_collective_api","title":"Collective Communication Operations","briefdescription":"","detaileddescription":"Collective communication operations must be called separately for each communicator in a communicator clique.They return when operations have been enqueued on the HIP stream. Since they may perform inter-CPU synchronization, each call has to be done from a different thread or process, or need to use Group Semantics (see below).","includes":[],"memberdefs":[{"kind":"function","id":"group__rccl__collective__api_1ga0353a2a2756a84bdc3404fd8ce17be95","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const void *","declname":"sendbuff","direction":"in","parameterdescription":"Local device data buffer to be reduced"},{"type":"void *","declname":"recvbuff","direction":"out","parameterdescription":"Data buffer where result is stored (only for root rank). May be null for other ranks."},{"type":"size_t","declname":"count","direction":"in","parameterdescription":"Number of elements in every send buffer"},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"ncclRedOp_t","declname":"op","direction":"in","parameterdescription":"Reduction operator type"},{"type":"int","declname":"root","direction":"in","parameterdescription":"Rank where result data array will be stored"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t ncclReduce","argsstring":"(const void *sendbuff, void *recvbuff, size_t count, ncclDataType_t datatype, ncclRedOp_t op, int root, ncclComm_t comm, hipStream_t stream)","name":"ncclReduce","briefdescription":"Reduce.","detaileddescription":"Reduces data arrays of length in into using operation. recvbuff* may be NULL on all calls except for root device. root* is the rank (not the HIP device) where data will reside after the operation is complete. In-place operation will happen if sendbuff == recvbuff.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__collective__api_1ga088407ffe8b1b7dc7578a37006d22ab9","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"void *","declname":"buff","direction":"inout","parameterdescription":"Input array on root to be copied to other ranks. Output array for all ranks."},{"type":"size_t","declname":"count","direction":"in","parameterdescription":"Number of elements in data buffer"},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"int","declname":"root","direction":"in","parameterdescription":"Rank owning buffer to be copied to others"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t ncclBcast","argsstring":"(void *buff, size_t count, ncclDataType_t datatype, int root, ncclComm_t comm, hipStream_t stream)","name":"ncclBcast","briefdescription":"(Deprecated) Broadcast (in-place)","detaileddescription":"Copies values from to all other devices. root is the rank (not the CUDA device) where data resides before the operation is started. This operation is implicitly in-place.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__collective__api_1ga5b70cb9c7e6ba209baf5b72f387a08d7","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const void *","declname":"sendbuff","direction":"in","parameterdescription":"Data array to copy (if root). May be NULL for other ranks"},{"type":"void *","declname":"recvbuff","direction":"in","parameterdescription":"Data array to store received array"},{"type":"size_t","declname":"count","direction":"in","parameterdescription":"Number of elements in data buffer"},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"int","declname":"root","direction":"in","parameterdescription":"Rank of broadcast root"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t ncclBroadcast","argsstring":"(const void *sendbuff, void *recvbuff, size_t count, ncclDataType_t datatype, int root, ncclComm_t comm, hipStream_t stream)","name":"ncclBroadcast","briefdescription":"Broadcast.","detaileddescription":"Copies values from on to on all devices. root* is the rank (not the HIP device) where data resides before the operation is started. sendbuff* may be NULL on ranks other than . In-place operation will happen if == .","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__collective__api_1ga30da781a49c7935ce3cb0156ed57b438","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const void *","declname":"sendbuff","direction":"in","parameterdescription":"Input data array to reduce"},{"type":"void *","declname":"recvbuff","direction":"out","parameterdescription":"Data array to store reduced result array"},{"type":"size_t","declname":"count","direction":"in","parameterdescription":"Number of elements in data buffer"},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"ncclRedOp_t","declname":"op","direction":"in","parameterdescription":"Reduction operator"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t ncclAllReduce","argsstring":"(const void *sendbuff, void *recvbuff, size_t count, ncclDataType_t datatype, ncclRedOp_t op, ncclComm_t comm, hipStream_t stream)","name":"ncclAllReduce","briefdescription":"All-Reduce.","detaileddescription":"Reduces data arrays of length in using operation, and leaves identical copies of result on each . In-place operation will happen if sendbuff == recvbuff.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__collective__api_1ga4cea2983c15d34a0531e549b06790a3b","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const void *","declname":"sendbuff","direction":"in","parameterdescription":"Input data array to reduce"},{"type":"void *","declname":"recvbuff","direction":"out","parameterdescription":"Data array to store reduced result subarray"},{"type":"size_t","declname":"recvcount","direction":"in","parameterdescription":"Number of elements each rank receives"},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"ncclRedOp_t","declname":"op","direction":"in","parameterdescription":"Reduction operator"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t ncclReduceScatter","argsstring":"(const void *sendbuff, void *recvbuff, size_t recvcount, ncclDataType_t datatype, ncclRedOp_t op, ncclComm_t comm, hipStream_t stream)","name":"ncclReduceScatter","briefdescription":"Reduce-Scatter.","detaileddescription":"Reduces data in using operation and leaves reduced result scattered over the devices so that on rank i will contain the i-th block of the result. Assumes sendcount is equal to nranks*recvcount, which means that should have a size of at least nranks*recvcount elements. In-place operations will happen if recvbuff == sendbuff + rank * recvcount.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__collective__api_1gae076e5ed96c575703eb27c183f47c148","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const void *","declname":"sendbuff","direction":"in","parameterdescription":"Input data array to send"},{"type":"void *","declname":"recvbuff","direction":"out","parameterdescription":"Data array to store the gathered result"},{"type":"size_t","declname":"sendcount","direction":"in","parameterdescription":"Number of elements each rank sends"},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t ncclAllGather","argsstring":"(const void *sendbuff, void *recvbuff, size_t sendcount, ncclDataType_t datatype, ncclComm_t comm, hipStream_t stream)","name":"ncclAllGather","briefdescription":"All-Gather.","detaileddescription":"Each device gathers values from other GPUs into , receiving data from rank i at offset i*sendcount. Assumes recvcount is equal to nranks*sendcount, which means that recvbuff should have a size of at least nranks*sendcount elements. In-place operations will happen if sendbuff == recvbuff + rank * sendcount.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__collective__api_1gaaa66205aebc317e447cc596425edaa1e","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const void *","declname":"sendbuff","direction":"in","parameterdescription":"Data array to send"},{"type":"size_t","declname":"count","direction":"in","parameterdescription":"Number of elements to send"},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"int","declname":"peer","direction":"in","parameterdescription":"Peer rank to send to"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t ncclSend","argsstring":"(const void *sendbuff, size_t count, ncclDataType_t datatype, int peer, ncclComm_t comm, hipStream_t stream)","name":"ncclSend","briefdescription":"Send.","detaileddescription":"Send data from to rank . Rank needs to call ncclRecv with the same and the same as this rank. This operation is blocking for the GPU. If multiple ncclSend and ncclRecv operations need to progress concurrently to complete, they must be fused within a ncclGroupStart \/ ncclGroupEnd section.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__collective__api_1gab97b538f4b6f472e0b9edc12bb06f8f6","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"void *","declname":"recvbuff","direction":"out","parameterdescription":"Data array to receive"},{"type":"size_t","declname":"count","direction":"in","parameterdescription":"Number of elements to receive"},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"int","declname":"peer","direction":"in","parameterdescription":"Peer rank to send to"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t ncclRecv","argsstring":"(void *recvbuff, size_t count, ncclDataType_t datatype, int peer, ncclComm_t comm, hipStream_t stream)","name":"ncclRecv","briefdescription":"Receive.","detaileddescription":"Receive data from rank into . Rank needs to call ncclSend with the same datatype and the same count as this rank. This operation is blocking for the GPU. If multiple ncclSend and ncclRecv operations need to progress concurrently to complete, they must be fused within a ncclGroupStart\/ ncclGroupEnd section.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__collective__api_1ga0eaed41aeaafc5bcc7d08328ea03a06b","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const void *","declname":"sendbuff","direction":"in","parameterdescription":"Data array to send"},{"type":"void *","declname":"recvbuff","direction":"out","parameterdescription":"Data array to receive into on root."},{"type":"size_t","declname":"sendcount","direction":"in","parameterdescription":"Number of elements to send per rank"},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"int","declname":"root","direction":"in","parameterdescription":"Rank that receives data from all other ranks"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t ncclGather","argsstring":"(const void *sendbuff, void *recvbuff, size_t sendcount, ncclDataType_t datatype, int root, ncclComm_t comm, hipStream_t stream)","name":"ncclGather","briefdescription":"Gather.","detaileddescription":"Root device gathers values from other GPUs into , receiving data from rank i at offset i*sendcount. Assumes recvcount is equal to nranks*sendcount, which means that should have a size of at least nranks*sendcount elements. In-place operations will happen if sendbuff == recvbuff + rank * sendcount. recvbuff* may be NULL on ranks other than .","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__collective__api_1ga6ff13983986f2193eac841bb856c0857","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const void *","declname":"sendbuff","direction":"in","parameterdescription":"Data array to send (on root rank). May be NULL on other ranks."},{"type":"void *","declname":"recvbuff","direction":"out","parameterdescription":"Data array to receive partial subarray into"},{"type":"size_t","declname":"recvcount","direction":"in","parameterdescription":"Number of elements to receive per rank"},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"int","declname":"root","direction":"in","parameterdescription":"Rank that scatters data to all other ranks"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t ncclScatter","argsstring":"(const void *sendbuff, void *recvbuff, size_t recvcount, ncclDataType_t datatype, int root, ncclComm_t comm, hipStream_t stream)","name":"ncclScatter","briefdescription":"Scatter.","detaileddescription":"Scattered over the devices so that recvbuff on rank i will contain the i-th block of the data on root. Assumes sendcount is equal to nranks*recvcount, which means that should have a size of at least nranks*recvcount elements. In-place operations will happen if recvbuff == sendbuff + rank * recvcount.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__collective__api_1ga667131e427e7159bcfb16c2bf8287dfd","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const void *","declname":"sendbuff","direction":"in","parameterdescription":"Data array to send (contains blocks for each other rank)"},{"type":"void *","declname":"recvbuff","direction":"out","parameterdescription":"Data array to receive (contains blocks from each other rank)"},{"type":"size_t","declname":"count","direction":"in","parameterdescription":"Number of elements to send between each pair of ranks"},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t ncclAllToAll","argsstring":"(const void *sendbuff, void *recvbuff, size_t count, ncclDataType_t datatype, ncclComm_t comm, hipStream_t stream)","name":"ncclAllToAll","briefdescription":"All-To-All.","detaileddescription":"Device (i) send (j)th block of data to device (j) and be placed as (i)th block. Each block for sending\/receiving has elements, which means that and should have a size of nranks*count elements. In-place operation is NOT supported. It is the user's responsibility to ensure that sendbuff and recvbuff are distinct.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__collective__api_1ga191cbb7b99a5b28ff85a10c93082cd8b","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const void *","declname":"sendbuff","direction":"in","parameterdescription":"Data array to send (contains blocks for each other rank)"},{"type":"const size_t","declname":"sendcounts","direction":"in","parameterdescription":"Array containing number of elements to send to each participating rank"},{"type":"const size_t","declname":"sdispls","direction":"in","parameterdescription":"Array of offsets into sendbuff for each participating rank"},{"type":"void *","declname":"recvbuff","direction":"out","parameterdescription":"Data array to receive (contains blocks from each other rank)"},{"type":"const size_t","declname":"recvcounts","direction":"in","parameterdescription":"Array containing number of elements to receive from each participating rank"},{"type":"const size_t","declname":"rdispls","direction":"in","parameterdescription":"Array of offsets into recvbuff for each participating rank"},{"type":"ncclDataType_t","declname":"datatype","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t ncclAllToAllv","argsstring":"(const void *sendbuff, const size_t sendcounts[], const size_t sdispls[], void *recvbuff, const size_t recvcounts[], const size_t rdispls[], ncclDataType_t datatype, ncclComm_t comm, hipStream_t stream)","name":"ncclAllToAllv","briefdescription":"All-To-Allv.","detaileddescription":"Device (i) sends sendcounts[j] of data from offset sdispls[j] to device (j). At the same time, device (i) receives recvcounts[j] of data from device (j) to be placed at rdispls[j]. sendcounts, sdispls, recvcounts and rdispls are all measured in the units of datatype, not bytes. In-place operation will happen if sendbuff == recvbuff.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."}]}
{"id":"group__msccl__api","kind":"group","language":null,"prot":null,"compoundname":"msccl_api","title":"MSCCL Algorithm","briefdescription":"","detaileddescription":"API calls relating to the optional MSCCL algorithm datapath","includes":[],"memberdefs":[{"kind":"typedef","id":"group__msccl__api_1ga67330717c515e3f41d5c589a84d8fd51","prot":"public","static":"no","type":"int","definition":"typedef int mscclAlgoHandle_t","argsstring":null,"name":"mscclAlgoHandle_t","briefdescription":"Opaque handle to MSCCL algorithm.","detaileddescription":null,"inbodydescription":null,"initializer":null},{"kind":"function","id":"group__msccl__api_1gafc8446f6990399459ea17c3844cb53fd","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const char *","declname":"mscclAlgoFilePath","direction":"in","parameterdescription":"Path to MSCCL algorithm file"},{"type":"mscclAlgoHandle_t *","declname":"mscclAlgoHandle","direction":"out","parameterdescription":"Returned handle to MSCCL algorithm"},{"type":"int","declname":"rank","direction":"in","parameterdescription":"Current rank"}],"type":"ncclResult_t","definition":"ncclResult_t mscclLoadAlgo","argsstring":"(const char *mscclAlgoFilePath, mscclAlgoHandle_t *mscclAlgoHandle, int rank)","name":"mscclLoadAlgo","briefdescription":"MSCCL Load Algorithm.","detaileddescription":"Load MSCCL algorithm file specified in mscclAlgoFilePath and return its handle via mscclAlgoHandle. This API is expected to be called by MSCCL scheduler instead of end users.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__msccl__api_1ga59c37e39ac3733bef3c84d4b2f1243a4","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"const void *","declname":"sendBuff","direction":"in","parameterdescription":"Data array to send"},{"type":"const size_t","declname":"sendCounts","direction":"in","parameterdescription":"Array containing number of elements to send to each participating rank"},{"type":"const size_t","declname":"sDisPls","direction":"in","parameterdescription":"Array of offsets into sendbuff for each participating rank"},{"type":"void *","declname":"recvBuff","direction":"out","parameterdescription":"Data array to receive"},{"type":"const size_t","declname":"recvCounts","direction":"in","parameterdescription":"Array containing number of elements to receive from each participating rank"},{"type":"const size_t","declname":"rDisPls","direction":"in","parameterdescription":"Array of offsets into recvbuff for each participating rank"},{"type":"size_t","declname":"count","direction":"in","parameterdescription":"Number of elements"},{"type":"ncclDataType_t","declname":"dataType","direction":"in","parameterdescription":"Data buffer element datatype"},{"type":"int","declname":"root","direction":"in","parameterdescription":"Root rank index"},{"type":"int","declname":"peer","direction":"in","parameterdescription":"Peer rank index"},{"type":"ncclRedOp_t","declname":"op","direction":"in","parameterdescription":"Reduction operator"},{"type":"mscclAlgoHandle_t","declname":"mscclAlgoHandle","direction":"in","parameterdescription":"Handle to MSCCL algorithm"},{"type":"ncclComm_t","declname":"comm","direction":"in","parameterdescription":"Communicator group object to execute on"},{"type":"hipStream_t","declname":"stream","direction":"in","parameterdescription":"HIP stream to execute collective on"}],"type":"ncclResult_t","definition":"ncclResult_t mscclRunAlgo","argsstring":"(const void *sendBuff, const size_t sendCounts[], const size_t sDisPls[], void *recvBuff, const size_t recvCounts[], const size_t rDisPls[], size_t count, ncclDataType_t dataType, int root, int peer, ncclRedOp_t op, mscclAlgoHandle_t mscclAlgoHandle, ncclComm_t comm, hipStream_t stream)","name":"mscclRunAlgo","briefdescription":"MSCCL Run Algorithm.","detaileddescription":"Run MSCCL algorithm specified by mscclAlgoHandle. The parameter list merges all possible parameters required by different operations as this is a general-purposed API. This API is expected to be called by MSCCL scheduler instead of end users.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__msccl__api_1gafdb450531b5feeb3df5649e6bbef794e","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[{"type":"mscclAlgoHandle_t","declname":"mscclAlgoHandle","direction":"in","parameterdescription":"Handle to MSCCL algorithm to unload"}],"type":"ncclResult_t","definition":"ncclResult_t mscclUnloadAlgo","argsstring":"(mscclAlgoHandle_t mscclAlgoHandle)","name":"mscclUnloadAlgo","briefdescription":"MSCCL Unload Algorithm.","detaileddescription":"Unload MSCCL algorithm previous loaded using its handle. This API is expected to be called by MSCCL scheduler instead of end users.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."}]}
{"id":"group__rccl__group__api","kind":"group","language":null,"prot":null,"compoundname":"rccl_group_api","title":"Group semantics","briefdescription":"","detaileddescription":"When managing multiple GPUs from a single thread, and since RCCL collective calls may perform inter-CPU synchronization, we need to \"group\" calls for different ranks\/devices into a single call.Grouping RCCL calls as being part of the same collective operation is done using ncclGroupStart and ncclGroupEnd. ncclGroupStart will enqueue all collective calls until the ncclGroupEnd call, which will wait for all calls to be complete. Note that for collective communication, ncclGroupEnd only guarantees that the operations are enqueued on the streams, not that the operation is effectively done.Both collective communication and ncclCommInitRank can be used in conjunction of ncclGroupStart\/ncclGroupEnd, but not together.Group semantics also allow to fuse multiple operations on the same device to improve performance (for aggregated collective calls), or to permit concurrent progress of multiple send\/receive operations.","includes":[],"memberdefs":[{"kind":"function","id":"group__rccl__group__api_1gaf81ec09dc19a44137a67958e5e209f2b","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[],"type":"ncclResult_t","definition":"ncclResult_t ncclGroupStart","argsstring":"()","name":"ncclGroupStart","briefdescription":"Group Start.","detaileddescription":"Start a group call. All calls to RCCL until ncclGroupEnd will be fused into a single RCCL operation. Nothing will be started on the HIP stream until ncclGroupEnd.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."},{"kind":"function","id":"group__rccl__group__api_1gafdeb850e3e594843faf8a98e8e86ec0c","prot":"public","static":"no","const":"no","explicit":"no","inline":"no","virt":"non-virtual","param":[],"type":"ncclResult_t","definition":"ncclResult_t ncclGroupEnd","argsstring":"()","name":"ncclGroupEnd","briefdescription":"Group End.","detaileddescription":"End a group call. Start a fused RCCL operation consisting of all calls since ncclGroupStart. Operations on the HIP stream depending on the RCCL operations need to be called after ncclGroupEnd.","inbodydescription":null,"initializer":null,"returns":"Result code. See Result Codes for more details."}]}
